<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Miles VT's Blog</title><link>https://milesvant.github.io/posts/</link><description>Recent content in Posts on Miles VT's Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 27 Oct 2022 16:26:37 -0700</lastBuildDate><atom:link href="https://milesvant.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>An Introduction to Diffusion Models</title><link>https://milesvant.github.io/posts/diffusion/</link><pubDate>Thu, 27 Oct 2022 16:26:37 -0700</pubDate><guid>https://milesvant.github.io/posts/diffusion/</guid><description>Introduction Denoising Diffusion Probabilisitc Models (&amp;ldquo;DDPMs&amp;rdquo; or just &amp;ldquo;Diffusion models&amp;rdquo;) have garnered significant interest as of late due to their use in the recent slate of amazing text-to-image models such as DALLÂ·E 2 and Stable Diffusion. In this post I will explain the basic mechanisms and math behind how these models work.
DDPMs (Sohl-Dickstein et al., 2015) are probabilistic generative models, meaning that they aim to learn an approximation for a target data distribution $q(x^{(0)})$.</description></item></channel></rss>